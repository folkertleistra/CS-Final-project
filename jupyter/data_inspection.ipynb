{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"private_outputs":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["## Data inspection\n","\n","This notebook was used to inspect the PMB data using Pandas\n","\n","Please note that this notebook is meant to be runned on the processed data that contains the Context-Gloss pairs."],"metadata":{"id":"yDPwfeDXTHZ4"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"goVxa5_0TDgw"},"outputs":[],"source":["import pandas as pd\n","#from google.colab import drive\n","import matplotlib.pyplot as plt\n","import collections\n","# drive.mount('/content/drive')"]},{"cell_type":"code","source":["# analyzing the longest sentence in our training corpus\n","train_path = '/data/processed/train.csv'\n","df_train = pd.read_csv(train_path, index_col=0)\n","\n","input_sequences = df_train['input']\n","max_length = input_sequences.str.len().max()\n","lens = [len(s) for s in input_sequences]\n","# Average length in training set\n","print(sum(lens) // len(lens))"],"metadata":{"id":"MN17gfboTW1I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate the frequency distribution\n","counter = collections.Counter(lens)\n","\n","# Plot the frequency distribution\n","plt.bar(counter.keys(), counter.values(), width=0.4)\n","plt.xlabel(\"Input Length\")\n","plt.ylabel(\"Frequency\")\n","plt.title('Input length Train split')\n","plt.show()"],"metadata":{"id":"z2qXgaOCTq-Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Display the median value\n","# Sort the list\n","lens.sort()\n","\n","# Find the middle value(s)\n","middle = len(lens) // 2\n","if len(lens) % 2 == 0:\n","    median = (lens[middle - 1] + lens[middle]) / 2\n","else:\n","    median = lens[middle]\n","\n","print(\"Median:\", median)"],"metadata":{"id":"mNBhUaFYMU6L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Inspect all our data together\n","train_path = '/data/processed/train.csv'\n","dev_path = '/data/processed/dev.csv'\n","test_path = '/data/processed/test.csv'\n","\n","train_df = pd.read_csv(train_path, index_col=0)\n","dev_df = pd.read_csv(dev_path, index_col=0)\n","test_df = pd.read_csv(test_path, index_col=0)\n","\n","print(f'Length of train: {len(train_df)}')\n","print(f'Length of dev: {len(dev_df)}')\n","print(f'Length of test: {len(test_df)}')\n","\n","\n","df_full = pd.concat([train_df, dev_df, test_df], axis=0)"],"metadata":{"id":"35K4oy9KMQG1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_full.head()\n","df_full[['input', 'labels', 'offset']].head()"],"metadata":{"id":"Em4oGQbQMUWN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Label distribution\n","print(train_df['labels'].value_counts())\n","print(dev_df['labels'].value_counts())\n","print(test_df['labels'].value_counts())"],"metadata":{"id":"J2BvpsUdMwK9"},"execution_count":null,"outputs":[]}]}