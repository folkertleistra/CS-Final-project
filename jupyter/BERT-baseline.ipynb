{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "1YsC_A-ZnfzkM5VzwPnjOOH_N78qfvTnW",
     "timestamp": 1639735178588
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9xEIoJ1xpdVD"
   },
   "source": [
    "## Notebook used for fine-tuning BERT-base on the PMB data\n",
    "\n",
    "The BERT base model is used as a baseline for this project.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XKVrr5U4lOn4",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1675333374969,
     "user_tz": -60,
     "elapsed": 6977,
     "user": {
      "displayName": "F.A. Leistra",
      "userId": "17579912925770168307"
     }
    },
    "outputId": "d593150d-d497-407e-e23f-f987c42872db"
   },
   "source": [
    "\n",
    "!pip install transformers"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.26.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.12.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ymo-hGggzZt2",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1675333377148,
     "user_tz": -60,
     "elapsed": 2187,
     "user": {
      "displayName": "F.A. Leistra",
      "userId": "17579912925770168307"
     }
    },
    "outputId": "415c9992-3b5d-4d64-ccbd-09cac435d320"
   },
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IZbv0Y9Q85oF",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1675333377148,
     "user_tz": -60,
     "elapsed": 4,
     "user": {
      "displayName": "F.A. Leistra",
      "userId": "17579912925770168307"
     }
    },
    "outputId": "c902335c-fbfe-4f04-86e0-f6c8a33138bd"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla T4\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hl7YK0bimuFr"
   },
   "source": [
    "# Importing all needed libraries for the project\n",
    "#!/usr/bin/env python\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "\n",
    "seeds = [42, 1234, 101, 160, 590]\n",
    "\n",
    "\n",
    "# Make reproducible as much as possible -> should run the experiments with 5 different seeds and report the standard deviations on the scores\n",
    "np.random.seed(seeds[4])\n",
    "tf.random.set_seed(seeds[4])\n",
    "python_random.seed(seeds[4])\n",
    "\n",
    "model_to_use = 'bert-base-uncased'\n",
    "batch_size = 32\n",
    "max_length = 256\n",
    "epochs = 1"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uu_y6-LnzSVW",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1675333377149,
     "user_tz": -60,
     "elapsed": 4,
     "user": {
      "displayName": "F.A. Leistra",
      "userId": "17579912925770168307"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "outputId": "6610c014-5435-4e65-99af-637dc54c7178"
   },
   "source": [
    "# Loading all the needed data\n",
    "import pandas as pd\n",
    "\n",
    "train_path = '/data/processed/train.csv'\n",
    "dev_path = '/data/processed/dev.csv'\n",
    "df_train = pd.read_csv(train_path, index_col=0)\n",
    "df_dev = pd.read_csv(dev_path, index_col=0)\n",
    "\n",
    "df_train.head()"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                           sent  \\\n",
       "0  A \"girl\" is styling her hair   \n",
       "1  A \"girl\" is styling her hair   \n",
       "2  A \"girl\" is styling her hair   \n",
       "3  A \"girl\" is styling her hair   \n",
       "4  A girl is styling her \"hair\"   \n",
       "\n",
       "                                                 sns labels  \\\n",
       "0                                girl: a young woman    Yes   \n",
       "1                     girl: a youthful female person     No   \n",
       "2                     girl: a female human offspring     No   \n",
       "3  girl: a girl or young woman with whom a man is...     No   \n",
       "4  hair: a covering for the body (or parts of it)...    Yes   \n",
       "\n",
       "                                               input    offset  \n",
       "0   A \"girl\" is styling her hair [SEP] a young woman  10129825  \n",
       "1  A \"girl\" is styling her hair [SEP] a youthful ...  10084295  \n",
       "2  A \"girl\" is styling her hair [SEP] a female hu...   9992837  \n",
       "3  A \"girl\" is styling her hair [SEP] a girl or y...  10130686  \n",
       "4  A girl is styling her \"hair\" [SEP] a covering ...   5254795  "
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-1c878693-1e41-483e-a14b-3c2d436d0d46\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>sns</th>\n",
       "      <th>labels</th>\n",
       "      <th>input</th>\n",
       "      <th>offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A \"girl\" is styling her hair</td>\n",
       "      <td>girl: a young woman</td>\n",
       "      <td>Yes</td>\n",
       "      <td>A \"girl\" is styling her hair [SEP] a young woman</td>\n",
       "      <td>10129825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A \"girl\" is styling her hair</td>\n",
       "      <td>girl: a youthful female person</td>\n",
       "      <td>No</td>\n",
       "      <td>A \"girl\" is styling her hair [SEP] a youthful ...</td>\n",
       "      <td>10084295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A \"girl\" is styling her hair</td>\n",
       "      <td>girl: a female human offspring</td>\n",
       "      <td>No</td>\n",
       "      <td>A \"girl\" is styling her hair [SEP] a female hu...</td>\n",
       "      <td>9992837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A \"girl\" is styling her hair</td>\n",
       "      <td>girl: a girl or young woman with whom a man is...</td>\n",
       "      <td>No</td>\n",
       "      <td>A \"girl\" is styling her hair [SEP] a girl or y...</td>\n",
       "      <td>10130686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A girl is styling her \"hair\"</td>\n",
       "      <td>hair: a covering for the body (or parts of it)...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>A girl is styling her \"hair\" [SEP] a covering ...</td>\n",
       "      <td>5254795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c878693-1e41-483e-a14b-3c2d436d0d46')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-1c878693-1e41-483e-a14b-3c2d436d0d46 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-1c878693-1e41-483e-a14b-3c2d436d0d46');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "-hMWuuqazSVX"
   },
   "source": [
    "#  Data tokenzier\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_to_use)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#Transform string labels to one-hot encodings\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "encoder = LabelBinarizer()\n",
    "Y_train_bin = encoder.fit_transform(df_train['labels'].to_list())  # Use encoder.classes_ to find mapping back\n",
    "Y_dev_bin = encoder.fit_transform(df_dev['labels'].to_list())\n",
    "print(Y_train_bin, type(Y_train_bin))\n",
    "\n",
    "Y_train = np.asarray([[i] for i in df_train['labels'].to_list()])\n",
    "Y_dev = np.asarray([[i] for i in df_dev['labels'].to_list()])\n",
    "print(Y_train)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YyQqIIOs42Vv",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1675333378583,
     "user_tz": -60,
     "elapsed": 515,
     "user": {
      "displayName": "F.A. Leistra",
      "userId": "17579912925770168307"
     }
    },
    "outputId": "b0732c90-0ceb-4b6f-a706-06859efc487a"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]] <class 'numpy.ndarray'>\n",
      "[['Yes']\n",
      " ['No']\n",
      " ['No']\n",
      " ...\n",
      " ['No']\n",
      " ['No']\n",
      " ['No']]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in df_train['input'].to_list():\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = max_length,          # Pad & truncate all sentences.\n",
    "                        padding='max_length',\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "train_input_ids = torch.cat(input_ids, dim=0)\n",
    "train_attention_masks = torch.cat(attention_masks, dim=0)\n",
    "train_labels = torch.tensor(Y_train_bin)"
   ],
   "metadata": {
    "id": "OBkq5BfE4oAm"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "y6NZYlUUzSVY"
   },
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in df_dev['input'].to_list():\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = max_length,          # Pad & truncate all sentences.\n",
    "                        padding='max_length',\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "dev_input_ids = torch.cat(input_ids, dim=0)\n",
    "dev_attention_masks = torch.cat(attention_masks, dim=0)\n",
    "dev_labels = torch.tensor(Y_dev_bin)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "\n",
    "\n",
    "# Combine the training inputs into a TensorDataset.\n",
    "train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n",
    "dev_dataset = TensorDataset(dev_input_ids, dev_attention_masks, dev_labels)\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "        train_dataset,  # The training samples.\n",
    "        sampler = SequentialSampler(train_dataset),  # Training data is already randomized\n",
    "        batch_size = batch_size  # Train with this batch size.\n",
    "    )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "dev_dataloader = DataLoader(\n",
    "            dev_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(dev_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ],
   "metadata": {
    "id": "REvMc1b_6NXa"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model training"
   ],
   "metadata": {
    "id": "CVVshxW_AalW"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AsqhrYBSj4CL",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1675333405080,
     "user_tz": -60,
     "elapsed": 3401,
     "user": {
      "displayName": "F.A. Leistra",
      "userId": "17579912925770168307"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5625e661-ed36-4633-f3b8-32898d6981ec"
   },
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    model_to_use,\n",
    "    num_labels = 2,           \n",
    "    output_attentions = False,      \n",
    "    output_hidden_states = False,  \n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()\n",
    "\n",
    "# Resizes input token embeddings matrix to account for the new special tokens\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Embedding(30522, 768, padding_idx=0)"
      ]
     },
     "metadata": {},
     "execution_count": 65
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "ZaUj2veQzSVb",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1675333405826,
     "user_tz": -60,
     "elapsed": 754,
     "user": {
      "displayName": "F.A. Leistra",
      "userId": "17579912925770168307"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5a2370aa-c756-463d-9a7d-4dfe581ceddd"
   },
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (2, 768)\n",
      "classifier.bias                                                 (2,)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ExmKPvL9rs3S",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1675333405827,
     "user_tz": -60,
     "elapsed": 10,
     "user": {
      "displayName": "F.A. Leistra",
      "userId": "17579912925770168307"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "900703fb-327f-45b0-a079-3491647ab68b"
   },
   "source": [
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5,\n",
    "                  eps = 1e-8\n",
    "                )\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train"
   ],
   "metadata": {
    "id": "pAh93xCQCMGp"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ],
   "metadata": {
    "id": "T2Qa1wnpCQhW"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ],
   "metadata": {
    "id": "xkHzNcVpCURc"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from torch._C import ListType\n",
    "from traitlets.traitlets import default\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "\n",
    "predictions, true_labels = defaultdict(list), defaultdict(list)\n",
    "val_losses = {}\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# We'll store a number of quantities such as training and validation loss, \n",
    "# validation accuracy, and timings.\n",
    "training_stats = []\n",
    "    \n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains four pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        #   [3]: tweet ids\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # In PyTorch, calling `model` will in turn call the model's `forward` \n",
    "        # function and pass down the arguments. The `forward` function is \n",
    "        # documented here: \n",
    "        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
    "        # The results are returned in a results object, documented here:\n",
    "        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
    "        # Specifically, we'll get the loss (because we provided labels) and the\n",
    "        # \"logits\"--the model outputs prior to activation.\n",
    "        result = model(b_input_ids, \n",
    "                       token_type_ids=None, \n",
    "                       attention_mask=b_input_mask, \n",
    "                       labels=b_labels,\n",
    "                       return_dict=True)\n",
    "\n",
    "        loss = result.loss\n",
    "        logits = result.logits\n",
    "        \n",
    "        # 'logits' is a 2D tensor with lists of logit lists\n",
    "        # 'b_labels' is a 1D tensor of the true label\n",
    "        # 'b_ids' is a 1D tensor of the tweet IDs\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.3f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(training_time))\n",
    "\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in dev_dataloader:\n",
    "        \n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        #   [3]: tweet ids\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            result = model(b_input_ids, \n",
    "                           token_type_ids=None, \n",
    "                           attention_mask=b_input_mask,\n",
    "                           labels=b_labels,\n",
    "                           return_dict=True)\n",
    "\n",
    "        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
    "        # output values prior to applying an activation function like the \n",
    "        # softmax.\n",
    "        loss = result.loss\n",
    "        logits = result.logits\n",
    "            \n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # dit overschrijft nu, maar moet append zijn #TODO\n",
    "        true_labels[epoch_i].append(label_ids)\n",
    "        predictions[epoch_i].append(logits)\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(dev_dataloader)\n",
    "    print(\"  Accuracy: {0:.3f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(dev_dataloader)\n",
    "    val_losses[epoch_i] = avg_val_loss\n",
    "\n",
    "    # If the avg_val_loss is lower than the previous recorded, save to dict\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.3f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-UKY_SI3CZAh",
    "outputId": "94360268-26c8-48de-8096-3aa216ca56e5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1675335919053,
     "user_tz": -60,
     "elapsed": 2513233,
     "user": {
      "displayName": "F.A. Leistra",
      "userId": "17579912925770168307"
     }
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "======== Epoch 1 / 1 ========\n",
      "Training...\n",
      "  Batch    40  of  1,764.    Elapsed: 0:00:47.\n",
      "  Batch    80  of  1,764.    Elapsed: 0:01:35.\n",
      "  Batch   120  of  1,764.    Elapsed: 0:02:24.\n",
      "  Batch   160  of  1,764.    Elapsed: 0:03:14.\n",
      "  Batch   200  of  1,764.    Elapsed: 0:04:05.\n",
      "  Batch   240  of  1,764.    Elapsed: 0:04:57.\n",
      "  Batch   280  of  1,764.    Elapsed: 0:05:49.\n",
      "  Batch   320  of  1,764.    Elapsed: 0:06:41.\n",
      "  Batch   360  of  1,764.    Elapsed: 0:07:33.\n",
      "  Batch   400  of  1,764.    Elapsed: 0:08:25.\n",
      "  Batch   440  of  1,764.    Elapsed: 0:09:17.\n",
      "  Batch   480  of  1,764.    Elapsed: 0:10:09.\n",
      "  Batch   520  of  1,764.    Elapsed: 0:11:01.\n",
      "  Batch   560  of  1,764.    Elapsed: 0:11:53.\n",
      "  Batch   600  of  1,764.    Elapsed: 0:12:45.\n",
      "  Batch   640  of  1,764.    Elapsed: 0:13:37.\n",
      "  Batch   680  of  1,764.    Elapsed: 0:14:29.\n",
      "  Batch   720  of  1,764.    Elapsed: 0:15:21.\n",
      "  Batch   760  of  1,764.    Elapsed: 0:16:12.\n",
      "  Batch   800  of  1,764.    Elapsed: 0:17:04.\n",
      "  Batch   840  of  1,764.    Elapsed: 0:17:56.\n",
      "  Batch   880  of  1,764.    Elapsed: 0:18:48.\n",
      "  Batch   920  of  1,764.    Elapsed: 0:19:40.\n",
      "  Batch   960  of  1,764.    Elapsed: 0:20:33.\n",
      "  Batch 1,000  of  1,764.    Elapsed: 0:21:25.\n",
      "  Batch 1,040  of  1,764.    Elapsed: 0:22:17.\n",
      "  Batch 1,080  of  1,764.    Elapsed: 0:23:09.\n",
      "  Batch 1,120  of  1,764.    Elapsed: 0:24:00.\n",
      "  Batch 1,160  of  1,764.    Elapsed: 0:24:52.\n",
      "  Batch 1,200  of  1,764.    Elapsed: 0:25:44.\n",
      "  Batch 1,240  of  1,764.    Elapsed: 0:26:36.\n",
      "  Batch 1,280  of  1,764.    Elapsed: 0:27:28.\n",
      "  Batch 1,320  of  1,764.    Elapsed: 0:28:20.\n",
      "  Batch 1,360  of  1,764.    Elapsed: 0:29:12.\n",
      "  Batch 1,400  of  1,764.    Elapsed: 0:30:04.\n",
      "  Batch 1,440  of  1,764.    Elapsed: 0:30:56.\n",
      "  Batch 1,480  of  1,764.    Elapsed: 0:31:48.\n",
      "  Batch 1,520  of  1,764.    Elapsed: 0:32:40.\n",
      "  Batch 1,560  of  1,764.    Elapsed: 0:33:31.\n",
      "  Batch 1,600  of  1,764.    Elapsed: 0:34:23.\n",
      "  Batch 1,640  of  1,764.    Elapsed: 0:35:15.\n",
      "  Batch 1,680  of  1,764.    Elapsed: 0:36:07.\n",
      "  Batch 1,720  of  1,764.    Elapsed: 0:36:59.\n",
      "  Batch 1,760  of  1,764.    Elapsed: 0:37:50.\n",
      "\n",
      "  Average training loss: 0.309\n",
      "  Training epoch took: 0:37:55\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.892\n",
      "  Validation Loss: 0.260\n",
      "  Validation took: 0:03:59\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:41:53 (h:mm:ss)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Display floats with three decimal places.\n",
    "pd.set_option('precision', 3)\n",
    "\n",
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# A hack to force the column headers to wrap.\n",
    "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "# Display the table.\n",
    "print(df_stats)\n",
    "\n",
    "best_val_loss  = min(val_losses, key=val_losses. get)\n",
    "print(best_val_loss)"
   ],
   "metadata": {
    "id": "VfU2Ks0CC2wV",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1675335919053,
     "user_tz": -60,
     "elapsed": 15,
     "user": {
      "displayName": "F.A. Leistra",
      "userId": "17579912925770168307"
     }
    },
    "outputId": "27fd9738-3eef-40d8-8e5b-04ba047ae25b"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
      "epoch                                                                         \n",
      "1              0.309         0.26          0.892       0:37:55         0:03:59\n",
      "0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#% matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.xticks(list(range(1, epochs + 1)))\n",
    "\n",
    "#plt.show()\n"
   ],
   "metadata": {
    "id": "Z_oCYJpTEttC",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1675335919053,
     "user_tz": -60,
     "elapsed": 9,
     "user": {
      "displayName": "F.A. Leistra",
      "userId": "17579912925770168307"
     }
    },
    "outputId": "dae61ac8-d70f-4dd5-c97f-83670fc79091"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x7fcd44419220>],\n",
       " <a list of 1 Text major ticklabel objects>)"
      ]
     },
     "metadata": {},
     "execution_count": 72
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "GVGnMabEK3EJ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Combine the results across all batches. \n",
    "flat_predictions = np.concatenate(predictions[best_val_loss], axis=0)\n",
    "\n",
    "# For each sample, pick the label (0 or 1) with the higher score.\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = np.concatenate(true_labels[best_val_loss], axis=0)"
   ],
   "metadata": {
    "id": "Qb-7YtIjE_f9"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(flat_true_labels, flat_predictions, digits=4))"
   ],
   "metadata": {
    "id": "x00SFHEOE7q-",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1675335919054,
     "user_tz": -60,
     "elapsed": 7,
     "user": {
      "displayName": "F.A. Leistra",
      "userId": "17579912925770168307"
     }
    },
    "outputId": "17597701-6adf-4995-e8e0-d1dfc0660419"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9402    0.9169    0.9284     11555\n",
      "           1     0.7489    0.8094    0.7780      3537\n",
      "\n",
      "    accuracy                         0.8917     15092\n",
      "   macro avg     0.8445    0.8632    0.8532     15092\n",
      "weighted avg     0.8954    0.8917    0.8932     15092\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "seed_0_clas = classification_report(flat_true_labels, flat_predictions, digits=4)"
   ],
   "metadata": {
    "id": "jYVtB7uBB8xh"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "test_path = '/data/processed/test.csv'\n",
    "df_test = pd.read_csv(test_path, index_col=0)\n",
    "Y_test_bin = encoder.fit_transform(df_test['labels'].to_list())  # Use encoder.classes_ to find mapping back\n",
    "Y_test = np.asarray([[i] for i in df_test['labels'].to_list()])\n",
    "\n",
    "# For every sentence...\n",
    "for sent in df_test['input'].to_list():\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = max_length,          # Pad & truncate all sentences.\n",
    "                        padding='max_length',\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "test_input_ids = torch.cat(input_ids, dim=0)\n",
    "test_attention_masks = torch.cat(attention_masks, dim=0)\n",
    "test_labels = torch.tensor(Y_test_bin)"
   ],
   "metadata": {
    "id": "a_sM8TTEqse4"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Combine the training inputs into a TensorDataset.\n",
    "test_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n",
    "\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "test_dataloader = DataLoader(\n",
    "            test_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(test_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ],
   "metadata": {
    "id": "Kl1mgTuksqur"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    " # Put the model in evaluation mode--the dropout layers behave differently\n",
    "# during evaluation.\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "total_eval_accuracy = 0\n",
    "total_eval_loss = 0\n",
    "nb_eval_steps = 0\n",
    "true_labels = []\n",
    "predictions = []\n",
    "\n",
    "# Evaluate data for one epoch\n",
    "for batch in test_dataloader:\n",
    "    \n",
    "    # Unpack this training batch from our dataloader. \n",
    "    #\n",
    "    # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "    # the `to` method.\n",
    "    #\n",
    "    # `batch` contains three pytorch tensors:\n",
    "    #   [0]: input ids \n",
    "    #   [1]: attention masks\n",
    "    #   [2]: labels \n",
    "    #   [3]: tweet ids\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[2].to(device)\n",
    "    \n",
    "    # Tell pytorch not to bother with constructing the compute graph during\n",
    "    # the forward pass, since this is only needed for backprop (training).\n",
    "    with torch.no_grad():        \n",
    "\n",
    "        # Forward pass, calculate logit predictions.\n",
    "        # token_type_ids is the same as the \"segment ids\", which \n",
    "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "        result = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask,\n",
    "                        labels=b_labels,\n",
    "                        return_dict=True)\n",
    "\n",
    "    # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
    "    # output values prior to applying an activation function like the \n",
    "    # softmax.\n",
    "    loss = result.loss\n",
    "    logits = result.logits\n",
    "        \n",
    "    # Accumulate the validation loss.\n",
    "    total_eval_loss += loss.item()\n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "    # dit overschrijft nu, maar moet append zijn #TODO\n",
    "    true_labels.append(label_ids)\n",
    "    predictions.append(logits)\n",
    "\n",
    "    # Calculate the accuracy for this batch of test sentences, and\n",
    "    # accumulate it over all batches.\n",
    "    total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "# Report the final accuracy for this validation run.\n",
    "avg_val_accuracy = total_eval_accuracy / len(dev_dataloader)\n",
    "print(\"  Accuracy: {0:.3f}\".format(avg_val_accuracy))\n",
    "\n",
    "# Calculate the average loss over all of the batches.\n",
    "avg_val_loss = total_eval_loss / len(dev_dataloader)\n",
    "val_losses[epoch_i] = avg_val_loss\n",
    "\n",
    "# If the avg_val_loss is lower than the previous recorded, save to dict\n",
    "\n",
    "# Measure how long the validation run took.\n",
    "validation_time = format_time(time.time() - t0)\n",
    "\n",
    "print(\"  Validation Loss: {0:.3f}\".format(avg_val_loss))\n",
    "print(\"  Validation took: {:}\".format(validation_time))"
   ],
   "metadata": {
    "id": "XYjNYyRTs8BE",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1675336045828,
     "user_tz": -60,
     "elapsed": 125273,
     "user": {
      "displayName": "F.A. Leistra",
      "userId": "17579912925770168307"
     }
    },
    "outputId": "cae9770f-1ffa-4922-f8f4-7f4fb8bc0eeb"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  Accuracy: 0.476\n",
      "  Validation Loss: 0.122\n",
      "  Validation took: 0:06:06\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Combine the results across all batches. \n",
    "flat_predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# For each sample, pick the label (0 or 1) with the higher score.\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "\n",
    "print(classification_report(flat_true_labels, flat_predictions, digits=4))"
   ],
   "metadata": {
    "id": "bQ_RSyL9db4-",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1675336045829,
     "user_tz": -60,
     "elapsed": 13,
     "user": {
      "displayName": "F.A. Leistra",
      "userId": "17579912925770168307"
     }
    },
    "outputId": "b8faccc2-0b76-4e64-afc6-b56c8188bbc5"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9473    0.9231    0.9350      6071\n",
      "           1     0.7690    0.8329    0.7997      1867\n",
      "\n",
      "    accuracy                         0.9019      7938\n",
      "   macro avg     0.8582    0.8780    0.8674      7938\n",
      "weighted avg     0.9053    0.9019    0.9032      7938\n",
      "\n"
     ]
    }
   ]
  }
 ]
}