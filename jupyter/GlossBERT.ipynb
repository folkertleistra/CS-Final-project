{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1LcsmMqVsBTmYNZm5TjFFMrA8Iz30VolR","timestamp":1675166160820},{"file_id":"1YsC_A-ZnfzkM5VzwPnjOOH_N78qfvTnW","timestamp":1639735178588}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"cells":[{"cell_type":"markdown","metadata":{"id":"9xEIoJ1xpdVD"},"source":["## Notebook used for fine-tuning GlossBERT on the PMB data\n","\n","\n","- For a sentence, find the target words that we want to disambiguate\n","- Generate context-gloss pairs for the target word -> use wordnet to obtain the senses for the target word and create a context-gloss pair for each sense\n","- Lets replicate the Sent-CLS-WS approach proposed in the gloss-bert paper as this resulted in the best scores and is pretty straight-forward.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XKVrr5U4lOn4","executionInfo":{"status":"ok","timestamp":1675368798910,"user_tz":-60,"elapsed":3674,"user":{"displayName":"M. Wouden, van","userId":"08558478764254559521"}},"outputId":"92de1539-fcde-46ba-b83c-c0f7e2324c13"},"source":["# all needed dependencies for this notebook\n","!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.26.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.12.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ymo-hGggzZt2","executionInfo":{"status":"ok","timestamp":1675368800755,"user_tz":-60,"elapsed":1887,"user":{"displayName":"M. Wouden, van","userId":"08558478764254559521"}},"outputId":"ec75adc3-008d-4c00-e64e-5e7ff94c3ebe"},"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IZbv0Y9Q85oF","executionInfo":{"status":"ok","timestamp":1675368802591,"user_tz":-60,"elapsed":1870,"user":{"displayName":"M. Wouden, van","userId":"08558478764254559521"}},"outputId":"a411e6bb-a38e-4207-8e9b-cf04c7ccf1c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla T4\n"]}]},{"cell_type":"code","metadata":{"id":"hl7YK0bimuFr"},"source":["# Importing all needed libraries for the project\n","#!/usr/bin/env python\n","\n","import numpy as np\n","import tensorflow as tf\n","import random as python_random\n","\n","seeds = [42, 1234, 101, 160, 590]\n","\n","\n","# Make reproducible as much as possible -> should run the experiments with 5 different seeds and report the standard deviations on the scores\n","# Change these values to set a different seed\n","np.random.seed(seeds[4])\n","tf.random.set_seed(seeds[4])\n","python_random.seed(seeds[4])\n","\n","batch_size = 32\n","max_length = 256\n","epochs = 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uu_y6-LnzSVW","executionInfo":{"status":"ok","timestamp":1675368805546,"user_tz":-60,"elapsed":445,"user":{"displayName":"M. Wouden, van","userId":"08558478764254559521"}},"colab":{"base_uri":"https://localhost:8080/","height":206},"outputId":"7ce1aa95-96d5-4fa8-f097-51d6b060ff13"},"source":["# Loading all the needed data\n","import pandas as pd\n","\n","train_path = '/data/processed/train.csv'\n","dev_path = '/data/processed/dev.csv'\n","df_train = pd.read_csv(train_path, index_col=0)\n","df_dev = pd.read_csv(dev_path, index_col=0)\n","\n","df_train.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                           sent  \\\n","0  A \"girl\" is styling her hair   \n","1  A \"girl\" is styling her hair   \n","2  A \"girl\" is styling her hair   \n","3  A \"girl\" is styling her hair   \n","4  A girl is styling her \"hair\"   \n","\n","                                                 sns labels  \\\n","0                                girl: a young woman    Yes   \n","1                     girl: a youthful female person     No   \n","2                     girl: a female human offspring     No   \n","3  girl: a girl or young woman with whom a man is...     No   \n","4  hair: a covering for the body (or parts of it)...    Yes   \n","\n","                                               input    offset  \n","0   A \"girl\" is styling her hair [SEP] a young woman  10129825  \n","1  A \"girl\" is styling her hair [SEP] a youthful ...  10084295  \n","2  A \"girl\" is styling her hair [SEP] a female hu...   9992837  \n","3  A \"girl\" is styling her hair [SEP] a girl or y...  10130686  \n","4  A girl is styling her \"hair\" [SEP] a covering ...   5254795  "],"text/html":["\n","  <div id=\"df-64943faf-ee9a-4292-870d-7a3e0f995dd0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sent</th>\n","      <th>sns</th>\n","      <th>labels</th>\n","      <th>input</th>\n","      <th>offset</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>A \"girl\" is styling her hair</td>\n","      <td>girl: a young woman</td>\n","      <td>Yes</td>\n","      <td>A \"girl\" is styling her hair [SEP] a young woman</td>\n","      <td>10129825</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A \"girl\" is styling her hair</td>\n","      <td>girl: a youthful female person</td>\n","      <td>No</td>\n","      <td>A \"girl\" is styling her hair [SEP] a youthful ...</td>\n","      <td>10084295</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>A \"girl\" is styling her hair</td>\n","      <td>girl: a female human offspring</td>\n","      <td>No</td>\n","      <td>A \"girl\" is styling her hair [SEP] a female hu...</td>\n","      <td>9992837</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>A \"girl\" is styling her hair</td>\n","      <td>girl: a girl or young woman with whom a man is...</td>\n","      <td>No</td>\n","      <td>A \"girl\" is styling her hair [SEP] a girl or y...</td>\n","      <td>10130686</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>A girl is styling her \"hair\"</td>\n","      <td>hair: a covering for the body (or parts of it)...</td>\n","      <td>Yes</td>\n","      <td>A girl is styling her \"hair\" [SEP] a covering ...</td>\n","      <td>5254795</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-64943faf-ee9a-4292-870d-7a3e0f995dd0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-64943faf-ee9a-4292-870d-7a3e0f995dd0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-64943faf-ee9a-4292-870d-7a3e0f995dd0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"-hMWuuqazSVX"},"source":["#  Data tokenzier\n","from transformers import AutoTokenizer\n","tokenizer = AutoTokenizer.from_pretrained('kanishka/GlossBERT')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Transform string labels to one-hot encodings\n","from sklearn.preprocessing import LabelBinarizer\n","encoder = LabelBinarizer()\n","Y_train_bin = encoder.fit_transform(df_train['labels'].to_list())  # Use encoder.classes_ to find mapping back\n","Y_dev_bin = encoder.fit_transform(df_dev['labels'].to_list())\n","print(Y_train_bin, type(Y_train_bin))\n","\n","Y_train = np.asarray([[i] for i in df_train['labels'].to_list()])\n","Y_dev = np.asarray([[i] for i in df_dev['labels'].to_list()])\n","print(Y_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YyQqIIOs42Vv","executionInfo":{"status":"ok","timestamp":1675368806701,"user_tz":-60,"elapsed":446,"user":{"displayName":"M. Wouden, van","userId":"08558478764254559521"}},"outputId":"bae60025-8c94-488d-8292-c35e41cf9d91"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1]\n"," [0]\n"," [0]\n"," ...\n"," [0]\n"," [0]\n"," [0]] <class 'numpy.ndarray'>\n","[['Yes']\n"," ['No']\n"," ['No']\n"," ...\n"," ['No']\n"," ['No']\n"," ['No']]\n"]}]},{"cell_type":"code","source":["# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","attention_masks = []\n","\n","# For every sentence...\n","for sent in df_train['input'].to_list():\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = max_length,          # Pad & truncate all sentences.\n","                        padding='max_length',\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","train_input_ids = torch.cat(input_ids, dim=0)\n","train_attention_masks = torch.cat(attention_masks, dim=0)\n","train_labels = torch.tensor(Y_train_bin)"],"metadata":{"id":"OBkq5BfE4oAm"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"y6NZYlUUzSVY"},"source":["# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","attention_masks = []\n","\n","# For every sentence...\n","for sent in df_dev['input'].to_list():\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = max_length,          # Pad & truncate all sentences.\n","                        padding='max_length',\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","dev_input_ids = torch.cat(input_ids, dim=0)\n","dev_attention_masks = torch.cat(attention_masks, dim=0)\n","dev_labels = torch.tensor(Y_dev_bin)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n","\n","\n","# Combine the training inputs into a TensorDataset.\n","train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n","dev_dataset = TensorDataset(dev_input_ids, dev_attention_masks, dev_labels)\n","\n","# Create the DataLoaders for our training and validation sets.\n","# We'll take training samples in random order. \n","train_dataloader = DataLoader(\n","        train_dataset,  # The training samples.\n","        sampler = SequentialSampler(train_dataset),  # Training data is already randomized\n","        batch_size = batch_size  # Train with this batch size.\n","    )\n","\n","# For validation the order doesn't matter, so we'll just read them sequentially.\n","dev_dataloader = DataLoader(\n","            dev_dataset, # The validation samples.\n","            sampler = SequentialSampler(dev_dataset), # Pull out batches sequentially.\n","            batch_size = batch_size # Evaluate with this batch size.\n","        )"],"metadata":{"id":"REvMc1b_6NXa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Model training"],"metadata":{"id":"CVVshxW_AalW"}},{"cell_type":"code","metadata":{"id":"AsqhrYBSj4CL","executionInfo":{"status":"ok","timestamp":1675368840335,"user_tz":-60,"elapsed":3680,"user":{"displayName":"M. Wouden, van","userId":"08558478764254559521"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"79221366-e663-4304-d52d-523ebc04656a"},"source":["from transformers import BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n","import torch\n","\n","# Load BertForSequenceClassification, the pretrained BERT model with a single \n","# linear classification layer on top. \n","model = BertForSequenceClassification.from_pretrained(\n","    'kanishka/GlossBERT',\n","    num_labels = 2,           \n","    output_attentions = False,      \n","    output_hidden_states = False,  \n",")\n","\n","# Tell pytorch to run this model on the GPU.\n","model.cuda()\n","\n","# Resizes input token embeddings matrix to account for the new special tokens\n","model.resize_token_embeddings(len(tokenizer))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Embedding(30522, 768, padding_idx=0)"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"ZaUj2veQzSVb","executionInfo":{"status":"ok","timestamp":1675368840337,"user_tz":-60,"elapsed":54,"user":{"displayName":"M. Wouden, van","userId":"08558478764254559521"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b04a177e-0440-4a93-a082-03070088d632"},"source":["# Get all of the model's parameters as a list of tuples.\n","params = list(model.named_parameters())\n","\n","print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n","\n","print('==== Embedding Layer ====\\n')\n","\n","for p in params[0:5]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== First Transformer ====\\n')\n","\n","for p in params[5:21]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== Output Layer ====\\n')\n","\n","for p in params[-4:]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The BERT model has 201 different named parameters.\n","\n","==== Embedding Layer ====\n","\n","bert.embeddings.word_embeddings.weight                  (30522, 768)\n","bert.embeddings.position_embeddings.weight                (512, 768)\n","bert.embeddings.token_type_embeddings.weight                (2, 768)\n","bert.embeddings.LayerNorm.weight                              (768,)\n","bert.embeddings.LayerNorm.bias                                (768,)\n","\n","==== First Transformer ====\n","\n","bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n","bert.encoder.layer.0.attention.self.query.bias                (768,)\n","bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n","bert.encoder.layer.0.attention.self.key.bias                  (768,)\n","bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n","bert.encoder.layer.0.attention.self.value.bias                (768,)\n","bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n","bert.encoder.layer.0.attention.output.dense.bias              (768,)\n","bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n","bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n","bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n","bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n","bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n","bert.encoder.layer.0.output.dense.bias                        (768,)\n","bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n","bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n","\n","==== Output Layer ====\n","\n","bert.pooler.dense.weight                                  (768, 768)\n","bert.pooler.dense.bias                                        (768,)\n","classifier.weight                                           (2, 768)\n","classifier.bias                                                 (2,)\n"]}]},{"cell_type":"code","metadata":{"id":"ExmKPvL9rs3S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675368840338,"user_tz":-60,"elapsed":51,"user":{"displayName":"M. Wouden, van","userId":"08558478764254559521"}},"outputId":"69889821-f229-4aa8-9b2a-7fbc977052b2"},"source":["optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5,\n","                  eps = 1e-8\n","                )\n","\n","from transformers import get_linear_schedule_with_warmup\n","\n","# Total number of training steps is [number of batches] x [number of epochs]. \n","# (Note that this is not the same as the number of training samples).\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["# Train"],"metadata":{"id":"pAh93xCQCMGp"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"metadata":{"id":"T2Qa1wnpCQhW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","import datetime\n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"metadata":{"id":"xkHzNcVpCURc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch._C import ListType\n","from traitlets.traitlets import default\n","import random\n","import numpy as np\n","import os\n","import glob\n","from collections import defaultdict\n","\n","predictions, true_labels = defaultdict(list), defaultdict(list)\n","val_losses = {}\n","\n","# Set the seed value all over the place to make this reproducible.\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# We'll store a number of quantities such as training and validation loss, \n","# validation accuracy, and timings.\n","training_stats = []\n","    \n","# Measure the total training time for the whole run.\n","total_t0 = time.time()\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","\n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    # Perform one full pass over the training set.\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    # Reset the total loss for this epoch.\n","    total_train_loss = 0\n","\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","            \n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n","        # `to` method.\n","        #\n","        # `batch` contains four pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        #   [3]: tweet ids\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        # Always clear any previously calculated gradients before performing a\n","        # backward pass. PyTorch doesn't do this automatically because \n","        # accumulating the gradients is \"convenient while training RNNs\". \n","        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n","        model.zero_grad()        \n","\n","        # Perform a forward pass (evaluate the model on this training batch).\n","        # In PyTorch, calling `model` will in turn call the model's `forward` \n","        # function and pass down the arguments. The `forward` function is \n","        # documented here: \n","        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n","        # The results are returned in a results object, documented here:\n","        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n","        # Specifically, we'll get the loss (because we provided labels) and the\n","        # \"logits\"--the model outputs prior to activation.\n","        result = model(b_input_ids, \n","                       token_type_ids=None, \n","                       attention_mask=b_input_mask, \n","                       labels=b_labels,\n","                       return_dict=True)\n","\n","        loss = result.loss\n","        logits = result.logits\n","        \n","        # 'logits' is a 2D tensor with lists of logit lists\n","        # 'b_labels' is a 1D tensor of the true label\n","        # 'b_ids' is a 1D tensor of the tweet IDs\n","\n","        # Accumulate the training loss over all of the batches so that we can\n","        # calculate the average loss at the end. `loss` is a Tensor containing a\n","        # single value; the `.item()` function just returns the Python value \n","        # from the tensor.\n","        total_train_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # Update parameters and take a step using the computed gradient.\n","        # The optimizer dictates the \"update rule\"--how the parameters are\n","        # modified based on their gradients, the learning rate, etc.\n","        optimizer.step()\n","\n","        # Update the learning rate.\n","        scheduler.step()\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_train_loss = total_train_loss / len(train_dataloader)            \n","    \n","    # Measure how long this epoch took.\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.3f}\".format(avg_train_loss))\n","    print(\"  Training epoch took: {:}\".format(training_time))\n","\n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    # Put the model in evaluation mode--the dropout layers behave differently\n","    # during evaluation.\n","    model.eval()\n","\n","    # Tracking variables \n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    # Evaluate data for one epoch\n","    for batch in dev_dataloader:\n","        \n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using \n","        # the `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        #   [3]: tweet ids\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        \n","        # Tell pytorch not to bother with constructing the compute graph during\n","        # the forward pass, since this is only needed for backprop (training).\n","        with torch.no_grad():        \n","\n","            # Forward pass, calculate logit predictions.\n","            # token_type_ids is the same as the \"segment ids\", which \n","            # differentiates sentence 1 and 2 in 2-sentence tasks.\n","            result = model(b_input_ids, \n","                           token_type_ids=None, \n","                           attention_mask=b_input_mask,\n","                           labels=b_labels,\n","                           return_dict=True)\n","\n","        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n","        # output values prior to applying an activation function like the \n","        # softmax.\n","        loss = result.loss\n","        logits = result.logits\n","            \n","        # Accumulate the validation loss.\n","        total_eval_loss += loss.item()\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        \n","        # dit overschrijft nu, maar moet append zijn #TODO\n","        true_labels[epoch_i].append(label_ids)\n","        predictions[epoch_i].append(logits)\n","\n","        # Calculate the accuracy for this batch of test sentences, and\n","        # accumulate it over all batches.\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)\n","\n","    # Report the final accuracy for this validation run.\n","    avg_val_accuracy = total_eval_accuracy / len(dev_dataloader)\n","    print(\"  Accuracy: {0:.3f}\".format(avg_val_accuracy))\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_val_loss = total_eval_loss / len(dev_dataloader)\n","    val_losses[epoch_i] = avg_val_loss\n","\n","    # If the avg_val_loss is lower than the previous recorded, save to dict\n","    \n","    # Measure how long the validation run took.\n","    validation_time = format_time(time.time() - t0)\n","    \n","    print(\"  Validation Loss: {0:.3f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","\n","    # Record all statistics from this epoch.\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Valid. Loss': avg_val_loss,\n","            'Valid. Accur.': avg_val_accuracy,\n","            'Training Time': training_time,\n","            'Validation Time': validation_time\n","        }\n","    )\n","\n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-UKY_SI3CZAh","outputId":"0e4fac42-e461-4d95-872a-0dd5e0110f77","executionInfo":{"status":"ok","timestamp":1675371279272,"user_tz":-60,"elapsed":2438980,"user":{"displayName":"M. Wouden, van","userId":"08558478764254559521"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======== Epoch 1 / 1 ========\n","Training...\n","  Batch    40  of  1,764.    Elapsed: 0:00:52.\n","  Batch    80  of  1,764.    Elapsed: 0:01:42.\n","  Batch   120  of  1,764.    Elapsed: 0:02:32.\n","  Batch   160  of  1,764.    Elapsed: 0:03:23.\n","  Batch   200  of  1,764.    Elapsed: 0:04:13.\n","  Batch   240  of  1,764.    Elapsed: 0:05:03.\n","  Batch   280  of  1,764.    Elapsed: 0:05:54.\n","  Batch   320  of  1,764.    Elapsed: 0:06:44.\n","  Batch   360  of  1,764.    Elapsed: 0:07:34.\n","  Batch   400  of  1,764.    Elapsed: 0:08:24.\n","  Batch   440  of  1,764.    Elapsed: 0:09:15.\n","  Batch   480  of  1,764.    Elapsed: 0:10:05.\n","  Batch   520  of  1,764.    Elapsed: 0:10:55.\n","  Batch   560  of  1,764.    Elapsed: 0:11:46.\n","  Batch   600  of  1,764.    Elapsed: 0:12:36.\n","  Batch   640  of  1,764.    Elapsed: 0:13:26.\n","  Batch   680  of  1,764.    Elapsed: 0:14:17.\n","  Batch   720  of  1,764.    Elapsed: 0:15:07.\n","  Batch   760  of  1,764.    Elapsed: 0:15:57.\n","  Batch   800  of  1,764.    Elapsed: 0:16:48.\n","  Batch   840  of  1,764.    Elapsed: 0:17:38.\n","  Batch   880  of  1,764.    Elapsed: 0:18:28.\n","  Batch   920  of  1,764.    Elapsed: 0:19:19.\n","  Batch   960  of  1,764.    Elapsed: 0:20:09.\n","  Batch 1,000  of  1,764.    Elapsed: 0:20:59.\n","  Batch 1,040  of  1,764.    Elapsed: 0:21:50.\n","  Batch 1,080  of  1,764.    Elapsed: 0:22:40.\n","  Batch 1,120  of  1,764.    Elapsed: 0:23:30.\n","  Batch 1,160  of  1,764.    Elapsed: 0:24:21.\n","  Batch 1,200  of  1,764.    Elapsed: 0:25:11.\n","  Batch 1,240  of  1,764.    Elapsed: 0:26:01.\n","  Batch 1,280  of  1,764.    Elapsed: 0:26:51.\n","  Batch 1,320  of  1,764.    Elapsed: 0:27:42.\n","  Batch 1,360  of  1,764.    Elapsed: 0:28:32.\n","  Batch 1,400  of  1,764.    Elapsed: 0:29:22.\n","  Batch 1,440  of  1,764.    Elapsed: 0:30:13.\n","  Batch 1,480  of  1,764.    Elapsed: 0:31:03.\n","  Batch 1,520  of  1,764.    Elapsed: 0:31:53.\n","  Batch 1,560  of  1,764.    Elapsed: 0:32:44.\n","  Batch 1,600  of  1,764.    Elapsed: 0:33:34.\n","  Batch 1,640  of  1,764.    Elapsed: 0:34:24.\n","  Batch 1,680  of  1,764.    Elapsed: 0:35:15.\n","  Batch 1,720  of  1,764.    Elapsed: 0:36:05.\n","  Batch 1,760  of  1,764.    Elapsed: 0:36:55.\n","\n","  Average training loss: 0.190\n","  Training epoch took: 0:36:59\n","\n","Running Validation...\n","  Accuracy: 0.939\n","  Validation Loss: 0.171\n","  Validation took: 0:03:40\n","\n","Training complete!\n","Total training took 0:40:39 (h:mm:ss)\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Display floats with three decimal places.\n","pd.set_option('precision', 3)\n","\n","# Create a DataFrame from our training statistics.\n","df_stats = pd.DataFrame(data=training_stats)\n","\n","# Use the 'epoch' as the row index.\n","df_stats = df_stats.set_index('epoch')\n","\n","# A hack to force the column headers to wrap.\n","#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n","\n","# Display the table.\n","print(df_stats)\n","\n","best_val_loss  = min(val_losses, key=val_losses. get)\n","print(best_val_loss)"],"metadata":{"id":"VfU2Ks0CC2wV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675371279274,"user_tz":-60,"elapsed":78,"user":{"displayName":"M. Wouden, van","userId":"08558478764254559521"}},"outputId":"acb0793d-2e36-4f55-a9ba-80b8330c5e18"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n","epoch                                                                         \n","1               0.19        0.171          0.939       0:36:59         0:03:40\n","0\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","#% matplotlib inline\n","\n","import seaborn as sns\n","\n","# Use plot styling from seaborn.\n","sns.set(style='darkgrid')\n","\n","# Increase the plot size and font size.\n","sns.set(font_scale=1.5)\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","# Plot the learning curve.\n","plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n","plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n","\n","# Label the plot.\n","plt.title(\"Training & Validation Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.xticks(list(range(1, epochs + 1)))\n","\n","#plt.show()\n"],"metadata":{"id":"Z_oCYJpTEttC","colab":{"base_uri":"https://localhost:8080/","height":462},"executionInfo":{"status":"ok","timestamp":1675371279275,"user_tz":-60,"elapsed":75,"user":{"displayName":"M. Wouden, van","userId":"08558478764254559521"}},"outputId":"7d5ce5e6-f19e-430e-9b65-9c649d2dbeac"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["([<matplotlib.axis.XTick at 0x7fcff5022730>],\n"," <a list of 1 Text major ticklabel objects>)"]},"metadata":{},"execution_count":18},{"output_type":"display_data","data":{"text/plain":["<Figure size 864x432 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":[],"metadata":{"id":"GVGnMabEK3EJ"}},{"cell_type":"code","source":["# Combine the results across all batches. \n","flat_predictions = np.concatenate(predictions[best_val_loss], axis=0)\n","\n","# For each sample, pick the label (0 or 1) with the higher score.\n","flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n","\n","# Combine the correct labels for each batch into a single list.\n","flat_true_labels = np.concatenate(true_labels[best_val_loss], axis=0)"],"metadata":{"id":"Qb-7YtIjE_f9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","\n","print(classification_report(flat_true_labels, flat_predictions, digits=4))"],"metadata":{"id":"x00SFHEOE7q-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675371279745,"user_tz":-60,"elapsed":538,"user":{"displayName":"M. Wouden, van","userId":"08558478764254559521"}},"outputId":"6f4cceed-7a2d-4ef6-f79c-0bf7ca596d48"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0     0.9594    0.9607    0.9600     11555\n","           1     0.8711    0.8671    0.8691      3537\n","\n","    accuracy                         0.9388     15092\n","   macro avg     0.9152    0.9139    0.9146     15092\n","weighted avg     0.9387    0.9388    0.9387     15092\n","\n"]}]},{"cell_type":"code","source":["seed_0_clas = classification_report(flat_true_labels, flat_predictions, digits=4)"],"metadata":{"id":"jYVtB7uBB8xh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","attention_masks = []\n","test_path = '/content/drive/Shareddrives/CS Final Project/data/processed/test.csv'\n","df_test = pd.read_csv(test_path, index_col=0)\n","Y_test_bin = encoder.fit_transform(df_test['labels'].to_list())  # Use encoder.classes_ to find mapping back\n","Y_test = np.asarray([[i] for i in df_test['labels'].to_list()])\n","\n","# For every sentence...\n","for sent in df_test['input'].to_list():\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = max_length,          # Pad & truncate all sentences.\n","                        padding='max_length',\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","test_input_ids = torch.cat(input_ids, dim=0)\n","test_attention_masks = torch.cat(attention_masks, dim=0)\n","test_labels = torch.tensor(Y_test_bin)"],"metadata":{"id":"a_sM8TTEqse4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Combine the training inputs into a TensorDataset.\n","test_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n","\n","\n","# For validation the order doesn't matter, so we'll just read them sequentially.\n","test_dataloader = DataLoader(\n","            test_dataset, # The validation samples.\n","            sampler = SequentialSampler(test_dataset), # Pull out batches sequentially.\n","            batch_size = batch_size # Evaluate with this batch size.\n","        )"],"metadata":{"id":"Kl1mgTuksqur"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" # Put the model in evaluation mode--the dropout layers behave differently\n","# during evaluation.\n","model.eval()\n","\n","# Tracking variables \n","total_eval_accuracy = 0\n","total_eval_loss = 0\n","nb_eval_steps = 0\n","true_labels = []\n","predictions = []\n","\n","# Evaluate data for one epoch\n","for batch in test_dataloader:\n","    \n","    # Unpack this training batch from our dataloader. \n","    #\n","    # As we unpack the batch, we'll also copy each tensor to the GPU using \n","    # the `to` method.\n","    #\n","    # `batch` contains three pytorch tensors:\n","    #   [0]: input ids \n","    #   [1]: attention masks\n","    #   [2]: labels \n","    #   [3]: tweet ids\n","    b_input_ids = batch[0].to(device)\n","    b_input_mask = batch[1].to(device)\n","    b_labels = batch[2].to(device)\n","    \n","    # Tell pytorch not to bother with constructing the compute graph during\n","    # the forward pass, since this is only needed for backprop (training).\n","    with torch.no_grad():        \n","\n","        # Forward pass, calculate logit predictions.\n","        # token_type_ids is the same as the \"segment ids\", which \n","        # differentiates sentence 1 and 2 in 2-sentence tasks.\n","        result = model(b_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=b_input_mask,\n","                        labels=b_labels,\n","                        return_dict=True)\n","\n","    # Get the loss and \"logits\" output by the model. The \"logits\" are the \n","    # output values prior to applying an activation function like the \n","    # softmax.\n","    loss = result.loss\n","    logits = result.logits\n","        \n","    # Accumulate the validation loss.\n","    total_eval_loss += loss.item()\n","\n","    # Move logits and labels to CPU\n","    logits = logits.detach().cpu().numpy()\n","    label_ids = b_labels.to('cpu').numpy()\n","    \n","    # dit overschrijft nu, maar moet append zijn #TODO\n","    true_labels.append(label_ids)\n","    predictions.append(logits)\n","\n","    # Calculate the accuracy for this batch of test sentences, and\n","    # accumulate it over all batches.\n","    total_eval_accuracy += flat_accuracy(logits, label_ids)\n","\n","# Report the final accuracy for this validation run.\n","avg_val_accuracy = total_eval_accuracy / len(dev_dataloader)\n","print(\"  Accuracy: {0:.3f}\".format(avg_val_accuracy))\n","\n","# Calculate the average loss over all of the batches.\n","avg_val_loss = total_eval_loss / len(dev_dataloader)\n","val_losses[epoch_i] = avg_val_loss\n","\n","# If the avg_val_loss is lower than the previous recorded, save to dict\n","\n","# Measure how long the validation run took.\n","validation_time = format_time(time.time() - t0)\n","\n","print(\"  Validation Loss: {0:.3f}\".format(avg_val_loss))\n","print(\"  Validation took: {:}\".format(validation_time))"],"metadata":{"id":"XYjNYyRTs8BE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675371397005,"user_tz":-60,"elapsed":116067,"user":{"displayName":"M. Wouden, van","userId":"08558478764254559521"}},"outputId":"ff71404c-dbec-4cd7-f91b-da79701fb97f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  Accuracy: 0.500\n","  Validation Loss: 0.078\n","  Validation took: 0:05:38\n"]}]},{"cell_type":"code","source":["# Combine the results across all batches. \n","flat_predictions = np.concatenate(predictions, axis=0)\n","\n","# For each sample, pick the label (0 or 1) with the higher score.\n","flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n","\n","# Combine the correct labels for each batch into a single list.\n","flat_true_labels = np.concatenate(true_labels, axis=0)\n","\n","\n","print(classification_report(flat_true_labels, flat_predictions, digits=4))"],"metadata":{"id":"bQ_RSyL9db4-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675371397007,"user_tz":-60,"elapsed":48,"user":{"displayName":"M. Wouden, van","userId":"08558478764254559521"}},"outputId":"174e09c0-5796-4410-bcf7-cc56dba9c18d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0     0.9666    0.9638    0.9652      6071\n","           1     0.8833    0.8918    0.8875      1867\n","\n","    accuracy                         0.9468      7938\n","   macro avg     0.9250    0.9278    0.9264      7938\n","weighted avg     0.9470    0.9468    0.9469      7938\n","\n"]}]}]}